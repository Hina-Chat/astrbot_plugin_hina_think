import re
import os
import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api.provider import LLMResponse
from openai.types.chat.chat_completion import ChatCompletion

@register("r1-filter", "Soulter", "å¯é¸æ“‡æ˜¯å¦éæ¿¾æ¨ç†æ¨¡å‹çš„æ€è€ƒå…§å®¹ï¼Œæ”¯æ´/thinkæŒ‡ä»¤æŸ¥çœ‹æ€ç¶­éˆï¼Œä¸¦å¯æŒä¹…åŒ–ä¿å­˜", "1.2.1", 'https://github.com/Soulter/astrbot_plugin_r1_filter')
class R1Filter(Star):
    def __init__(self, context: Context, config: dict):
        super().__init__(context)
        self.config = config
        self.display_reasoning_text = self.config.get('display_reasoning_text', True)
        self.max_think_length = self.config.get('max_think_length', 600)
        
        # åˆå§‹åŒ–æ—¥èªŒè¨˜éŒ„å™¨
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # æŒä¹…åŒ–ç›¸é—œé…ç½®
        self.enable_persistence = self.config.get('enable_persistence', True)  # æ˜¯å¦å•Ÿç”¨æŒä¹…åŒ–
        self.save_as_markdown = self.config.get('save_as_markdown', True)      # æ˜¯å¦ä¿å­˜ç‚ºMarkdown
        self.max_records_per_user = self.config.get('max_records_per_user', 50)   # æ¯ç”¨æˆ¶æœ€å¤§è¨˜éŒ„æ•¸
        self.max_file_size_mb = self.config.get('max_file_size_mb', 5)             # å–®å€‹æª”æ¡ˆæœ€å¤§å¤§å°(MB)
        self.records_per_file = self.config.get('records_per_file', 20)           # æ¯å€‹æª”æ¡ˆæœ€å¤§è¨˜éŒ„æ•¸
        
        # ä¿®å¤å­˜å‚¨ç›®å½•é…ç½®é€»è¾‘
        storage_dir_config = self.config.get('storage_dir', '')
        if storage_dir_config and storage_dir_config.strip():
            self.storage_dir = Path(storage_dir_config)
        else:
            # é è¨­å„²å­˜åœ¨æ’ä»¶ç›®éŒ„ä¸‹
            default_storage = Path(__file__).parent / 'r1_thoughts_data'
            self.storage_dir = default_storage
        
        # è¨˜æ†¶é«”ä¸­çš„æ€ç¶­éˆå¿«å–
        self.last_reasoning: Dict[str, str] = {}
        
        # åˆå§‹åŒ–å„²å­˜ç›®éŒ„
        self._init_storage()
        
        # è¼‰å…¥å·²æœ‰çš„æ€ç¶­éˆè¨˜éŒ„
        if self.enable_persistence:
            asyncio.create_task(self._load_cached_reasoning())
    
    def _init_storage(self):
        """åˆå§‹åŒ–å„²å­˜ç›®éŒ„çµæ§‹"""
        if not self.enable_persistence:
            return
            
        try:
            # å‰µå»ºä¸»ç›®éŒ„
            self.storage_dir.mkdir(parents=True, exist_ok=True)
            
            # å‰µå»ºå­ç›®éŒ„
            (self.storage_dir / 'json').mkdir(exist_ok=True)      # JSONæ ¼å¼åŸå§‹æ•¸æ“š
            (self.storage_dir / 'markdown').mkdir(exist_ok=True)  # Markdownæ ¼å¼å ±å‘Š
            (self.storage_dir / 'cache').mkdir(exist_ok=True)     # å¿«å–æª”æ¡ˆ
            
            self.logger.info(f"R1Filter: å„²å­˜ç›®éŒ„åˆå§‹åŒ–å®Œæˆ: {self.storage_dir}")
        except Exception as e:
            self.logger.error(f"R1Filter: å„²å­˜ç›®éŒ„åˆå§‹åŒ–å¤±æ•—: {e}")
            self.enable_persistence = False
    
    async def _load_cached_reasoning(self):
        """è¼‰å…¥å¿«å–çš„æ€ç¶­éˆè¨˜éŒ„"""
        if not self.enable_persistence:
            return
            
        cache_file = self.storage_dir / 'cache' / 'last_reasoning.json'
        try:
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.last_reasoning = json.load(f)
                self.logger.info(f"R1Filter: è¼‰å…¥äº† {len(self.last_reasoning)} æ¢å¿«å–è¨˜éŒ„")
        except Exception as e:
            self.logger.error(f"R1Filter: è¼‰å…¥å¿«å–å¤±æ•—: {e}")
    
    async def _save_reasoning_cache(self):
        """ä¿å­˜æ€ç¶­éˆå¿«å–åˆ°æª”æ¡ˆ"""
        if not self.enable_persistence:
            return
            
        cache_file = self.storage_dir / 'cache' / 'last_reasoning.json'
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.last_reasoning, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"R1Filter: ä¿å­˜å¿«å–å¤±æ•—: {e}")
    
    async def _save_reasoning_record(self, user_key: str, reasoning: str, response_text: str, event: AstrMessageEvent):
        """ä¿å­˜å®Œæ•´çš„æ€ç¶­éˆè¨˜éŒ„åˆ°æª”æ¡ˆ"""
        if not self.enable_persistence or not reasoning:
            return
            
        try:
            timestamp = datetime.now()
            
            # æº–å‚™è¨˜éŒ„æ•¸æ“š
            record = {
                'timestamp': timestamp.isoformat(),
                'user_key': user_key,
                'user_id': str(event.unified_msg_origin),
                'reasoning': reasoning,
                'response': response_text,
                'message_content': getattr(event, 'message_str', ''),
                'platform': getattr(event, 'platform', 'unknown')
            }
            
            # ä¿å­˜JSONæ ¼å¼
            await self._save_json_record(record, timestamp)
            
            # ä¿å­˜Markdownæ ¼å¼
            if self.save_as_markdown:
                await self._save_markdown_record(record, timestamp)
                
        except Exception as e:
            self.logger.error(f"R1Filter: ä¿å­˜æ€ç¶­è¨˜éŒ„å¤±æ•—: {e}")
    
    async def _save_json_record(self, record: dict, timestamp: datetime):
        """ä¿å­˜ JSON æ ¼å¼è¨˜éŒ„"""
        user_dir = self.storage_dir / 'json' / record['user_id']
        user_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸåˆ†çµ„æª”æ¡ˆ
        date_str = timestamp.strftime('%Y-%m-%d')
        json_file = user_dir / f'{date_str}.jsonl'
        
        # è¿½åŠ æ¨¡å¼å¯«å…¥JSONLæ ¼å¼
        with open(json_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')
        
        # æ¸…ç†èˆŠè¨˜éŒ„ï¼Œä¿æŒæ•¸é‡é™åˆ¶
        await self._cleanup_old_records(user_dir, 'json')
    
    async def _save_markdown_record(self, record: dict, timestamp: datetime):
        """ä¿å­˜ Markdown è¨˜éŒ„ - æŒ‰æ—¥æœŸå’Œæª”æ¡ˆå¤§å°åˆ†å‰²"""
        user_dir = self.storage_dir / 'markdown' / record['user_id']
        user_dir.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰æ—¥æœŸåˆ†çµ„ï¼Œä½†æ§åˆ¶æª”æ¡ˆå¤§å°
        date_str = timestamp.strftime('%Y-%m-%d')
        
        # å°‹æ‰¾åˆé©çš„æª”æ¡ˆ
        file_index = 1
        while True:
            if file_index == 1:
                md_file = user_dir / f'{date_str}_Hina_Think.md'
            else:
                md_file = user_dir / f'{date_str}_Hina_Think_{file_index}.md'
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”å¤§å°æ˜¯å¦è¶…éé™åˆ¶
            if md_file.exists():
                file_size_mb = md_file.stat().st_size / (1024 * 1024)
                record_count = self._count_records_in_md_file(md_file)
                
                if file_size_mb >= self.max_file_size_mb or record_count >= self.records_per_file:
                    file_index += 1
                    continue
            
            break
        
        # ç”ŸæˆMarkdownå…§å®¹
        md_content = self._generate_markdown_content(record, file_index)
        
        # è¿½åŠ æ¨¡å¼å¯«å…¥
        with open(md_file, 'a', encoding='utf-8') as f:
            if not md_file.exists() or md_file.stat().st_size == 0:
                f.write(f"# {record['user_id']} çš„æ€ç¶­éˆè¨˜éŒ„ - {date_str} (ç¬¬{file_index}éƒ¨åˆ†)\n\n")
            f.write(md_content)
    
    def _count_records_in_md_file(self, md_file: Path) -> int:
        """è¨ˆç®—Markdownæª”æ¡ˆä¸­çš„è¨˜éŒ„æ•¸é‡"""
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
                # è¨ˆç®—æ€ç¶­è¨˜éŒ„æ¨™é¡Œçš„æ•¸é‡
                return content.count('## æ€ç¶­è¨˜éŒ„')
        except:
            return 0
    
    def _generate_markdown_content(self, record: dict, file_index: int = 1) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„è¨˜éŒ„å…§å®¹"""
        timestamp = datetime.fromisoformat(record['timestamp'])
        
        # æ¸…ç†å’Œæ ¼å¼åŒ–æ€ç¶­å…§å®¹
        reasoning = self._format_reasoning_for_markdown(record['reasoning'])
        response = record['response'].strip()
        user_message = record['message_content'].strip()
        
        # è¨ˆç®—æ€ç¶­éˆé•·åº¦çµ±è¨ˆ
        reasoning_chars = len(reasoning)
        reasoning_lines = len(reasoning.split('\n'))
        
        md_content = f"""## æ€ç¶­è¨˜éŒ„ - {timestamp.strftime('%mæœˆ%dæ—¥ %H:%M:%S')}

> **çµ±è¨ˆè³‡è¨Š**: æ€ç¶­éˆ {reasoning_chars} å­—å…ƒï¼Œ{reasoning_lines} è¡Œ

### ä½¿ç”¨è€…
```
{user_message}
```

### éµå±±é››
<details>
<summary>ğŸ’­ é»æ“Šå±•é–‹æ€ç¶­éˆ ({reasoning_chars} å­—å…ƒ)</summary>

{reasoning}

</details>

### ğŸ’¬ æœ€çµ‚å›è¦†
{response}

---

"""
        return md_content
    
    def _format_reasoning_for_markdown(self, reasoning: str) -> str:
        """æ ¼å¼åŒ–æ€ç¶­å…§å®¹ç‚º Markdown å‹å¥½æ ¼å¼"""
        # ç§»é™¤å¤šé¤˜çš„ç©ºè¡Œ
        lines = [line.rstrip() for line in reasoning.split('\n')]
        
        # è™•ç†ç¨‹å¼ç¢¼å¡Š
        formatted_lines = []
        in_code_block = False
        
        for line in lines:
            # æª¢æ¸¬ç¨‹å¼ç¢¼ç›¸é—œçš„è¡Œ
            if any(keyword in line.lower() for keyword in ['```', 'code:', 'function', 'def ', 'class ', 'import ']):
                if not in_code_block and ('```' not in line):
                    formatted_lines.append('```')
                    in_code_block = True
                formatted_lines.append(line)
                if '```' in line and in_code_block:
                    in_code_block = False
            else:
                if in_code_block and line.strip() and not any(c.isalnum() for c in line):
                    formatted_lines.append('```')
                    in_code_block = False
                formatted_lines.append(line)
        
        if in_code_block:
            formatted_lines.append('```')
        
        return '\n'.join(formatted_lines)
    
    async def _cleanup_old_records(self, user_dir: Path, format_type: str):
        """æ¸…ç†èˆŠè¨˜éŒ„ï¼Œä¿æŒæ•¸é‡é™åˆ¶"""
        try:
            if format_type == 'json':
                files = list(user_dir.glob('*.jsonl'))
            else:
                files = list(user_dir.glob('*.md'))
            
            if len(files) > self.max_records_per_user:
                # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼Œåˆªé™¤æœ€èˆŠçš„æª”æ¡ˆ
                files.sort(key=lambda x: x.stat().st_mtime)
                for old_file in files[:-self.max_records_per_user]:
                    try:
                        old_file.unlink()
                        self.logger.info(f"R1Filter: å·²æ¸…ç†èˆŠæª”æ¡ˆ {old_file.name}")
                    except Exception as e:
                        self.logger.error(f"R1Filter: æ¸…ç†æª”æ¡ˆå¤±æ•— {old_file}: {e}")
        except Exception as e:
            self.logger.error(f"R1Filter: æ¸…ç†èˆŠè¨˜éŒ„å¤±æ•—: {e}")
    
    async def _get_user_conversation_key(self, event: AstrMessageEvent) -> str:
        """ç”Ÿæˆä½¿ç”¨è€…+æœƒè©±çš„å”¯ä¸€æ¨™è­˜éµ"""
        uid = event.unified_msg_origin
        try:
            curr_cid = await self.context.conversation_manager.get_curr_conversation_id(uid)
            return f"{uid}_{curr_cid}"
        except:
            return str(uid)
    
    def _extract_reasoning_content(self, response: LLMResponse) -> str:
        """å¾ LLM éŸ¿æ‡‰ä¸­æå–æ¨ç†å…§å®¹"""
        if not (response and response.raw_completion and isinstance(response.raw_completion, ChatCompletion)):
            return ""
        
        if not (len(response.raw_completion.choices) and response.raw_completion.choices[0].message):
            return ""
        
        message = response.raw_completion.choices[0].message
        reasoning_content = ""
        
        if hasattr(message, 'reasoning') and message.reasoning:
            reasoning_content = message.reasoning
        elif hasattr(message, 'reasoning_content') and message.reasoning_content:
            reasoning_content = message.reasoning_content
        
        return reasoning_content
    
    def _extract_reasoning_from_text(self, text: str) -> str:
        """å¾æ–‡å­—ä¸­æå–è¢« <think> æ¨™ç±¤åŒ…åœçš„æ¨ç†å…§å®¹"""
        if not text:
            return ""
        
        think_pattern = r'<think>(.*?)</think>'
        matches = re.findall(think_pattern, text, flags=re.DOTALL)
        
        if matches:
            return '\n\n'.join(match.strip() for match in matches)
        
        return ""
    
    @filter.on_llm_response()
    async def resp(self, event: AstrMessageEvent, response: LLMResponse):
        user_key = await self._get_user_conversation_key(event)
        reasoning_content = ""
        final_response_text = ""
        
        if self.display_reasoning_text:
            if response and response.raw_completion and isinstance(response.raw_completion, ChatCompletion):
                if len(response.raw_completion.choices) and response.raw_completion.choices[0].message:
                    message = response.raw_completion.choices[0].message

                    if hasattr(message, 'reasoning') and message.reasoning:
                        reasoning_content = message.reasoning
                    elif hasattr(message, 'reasoning_content') and message.reasoning_content:
                        reasoning_content = message.reasoning_content

                    if reasoning_content:
                        self.last_reasoning[user_key] = reasoning_content
                        final_response_text = message.content if message.content else ""
                        response.completion_text = f"æ€è€ƒï¼š{reasoning_content}\n\n{final_response_text}"
                    else:
                        final_response_text = message.content if message.content else response.completion_text
                        response.completion_text = final_response_text
        else: 
            completion_text = response.completion_text if response.completion_text else ""
            
            reasoning_from_raw = self._extract_reasoning_content(response)
            if reasoning_from_raw:
                reasoning_content = reasoning_from_raw
                self.last_reasoning[user_key] = reasoning_content
            else:
                reasoning_from_text = self._extract_reasoning_from_text(completion_text)
                if reasoning_from_text:
                    reasoning_content = reasoning_from_text
                    self.last_reasoning[user_key] = reasoning_content
            
            if '<think>' in completion_text or '</think>' in completion_text:
                completion_text = re.sub(r'<think>.*?</think>', '', completion_text, flags=re.DOTALL).strip()
                completion_text = completion_text.replace('<think>', '').replace('</think>', '').strip()
            
            final_response_text = completion_text
            response.completion_text = completion_text
        
        # ç•°æ­¥ä¿å­˜è¨˜éŒ„
        if reasoning_content:
            asyncio.create_task(self._save_reasoning_record(
                user_key, reasoning_content, final_response_text, event))
        
        # ç•°æ­¥ä¿å­˜å¿«å–
        if self.last_reasoning:
            asyncio.create_task(self._save_reasoning_cache())
    
    @filter.command("think", alias={'æ€è€ƒ', 'æ€ç¶­éˆ'})
    async def think_command(self, event: AstrMessageEvent):
        """é¡¯ç¤ºä¸Šæ¬¡å°è©±çš„æ€ç¶­éˆ"""
        user_key = await self._get_user_conversation_key(event)
        
        if user_key in self.last_reasoning and self.last_reasoning[user_key]:
            reasoning = self.last_reasoning[user_key]
            if len(reasoning) > self.max_think_length:
                reasoning = reasoning[:self.max_think_length] + "\n\n...(æš«ä¸”å¦‚æ­¤â€¦â€¦)"
            
            yield event.plain_result(f"ç§˜ç¥æµé››çš„å†…å¿ƒä¸–ç•Œï¼šï¼š\n\n{reasoning}")
        else:
            yield event.plain_result("éåº¦çš„æ€è€ƒæˆ–è¨±æ˜¯æ¯’è—¥å‘¢â€¦â€¦")
    
    @filter.command("think_clear", alias={'æ¸…ç©ºæ€è€ƒ', 'æ¸…ç†æ€ç¶­éˆ'})
    async def think_clear_command(self, event: AstrMessageEvent):
        """æ¸…ç©ºç•¶å‰ä½¿ç”¨è€…çš„æ€ç¶­éˆè¨˜éŒ„"""
        user_key = await self._get_user_conversation_key(event)
        
        if user_key in self.last_reasoning:
            del self.last_reasoning[user_key]
            # ç•°æ­¥ä¿å­˜å¿«å–
            asyncio.create_task(self._save_reasoning_cache())
            yield event.plain_result("éåº¦çš„æ€è€ƒæˆ–è¨±æ˜¯æ¯’è—¥å‘¢â€¦â€¦")
        else:
            yield event.plain_result("ç½å„å¿ƒè‡ªæŒï¼Œæˆ‘æ€æ•…æˆ‘åœ¨â€¦â€¦")
    
    @filter.command("think_status", alias={'ç‹€æ…‹'})
    async def think_status_command(self, event: AstrMessageEvent):
        """é¡¯ç¤ºæ’ä»¶ç‹€æ…‹è³‡è¨Š"""
        display_status = "ON" if self.display_reasoning_text else "OFF"
        persistence_status = "ON" if self.enable_persistence else "OFF"
        markdown_status = "ON" if self.save_as_markdown else "OFF"
        total_records = len(self.last_reasoning)
        user_key = await self._get_user_conversation_key(event)
        has_record = "å­˜" if user_key in self.last_reasoning else "æ»…"
        
        status_info = f"""ğŸ“Š R1æ€ç¶­éˆæ’ä»¶ç‹€æ…‹ï¼š
â€¢ æ€è€ƒå…§å®¹é¡¯ç¤º: {display_status}
â€¢ æŒä¹…åŒ–å„²å­˜: {persistence_status}
â€¢ Markdownä¿å­˜: {markdown_status}
â€¢ è¨˜æ†¶é«”è¨˜éŒ„æ•¸: {total_records}
â€¢ æ‚¨çš„æ€è€ƒè¨˜éŒ„: {has_record}
â€¢ å„²å­˜ç›®éŒ„: {self.storage_dir}
â€¢ æª”æ¡ˆå¤§å°é™åˆ¶: {self.max_file_size_mb}MB
â€¢ æ¯æª”æ¡ˆè¨˜éŒ„æ•¸: {self.records_per_file}æ¢

æŒ‡ä»¤:
â€¢ /think - æŸ¥çœ‹ä¸Šæ¬¡æ€è€ƒéç¨‹
â€¢ /think_clear - æ¸…ç©ºæ€è€ƒè¨˜éŒ„
â€¢ /think_status - æŸ¥çœ‹æ’ä»¶ç‹€æ…‹
â€¢ /think_export - åŒ¯å‡ºæ€ç¶­è¨˜éŒ„
â€¢ /think_stats - æŸ¥çœ‹å„²å­˜çµ±è¨ˆ"""
        
        yield event.plain_result(status_info)
    
    @filter.command("think_export", alias={'åŒ¯å‡ºæ€ç¶­', 'å°å‡ºè¨˜éŒ„'})
    async def think_export_command(self, event: AstrMessageEvent):
        """åŒ¯å‡ºç•¶å‰ä½¿ç”¨è€…çš„æ€ç¶­è¨˜éŒ„æª”æ¡ˆè·¯å¾‘"""
        if not self.enable_persistence:
            yield event.plain_result("è‹¥æ˜¯æ²’æœ‰æ—¥è¨˜æœ¬ï¼Œé‚£æ€éº½è¨˜æ—¥è¨˜å‘¢ï¼ˆç¬‘ï¼‰")
            return
        
        user_id = str(event.unified_msg_origin)
        json_dir = self.storage_dir / 'json' / user_id
        md_dir = self.storage_dir / 'markdown' / user_id
        
        json_files = list(json_dir.glob('*.jsonl')) if json_dir.exists() else []
        md_files = list(md_dir.glob('*.md')) if md_dir.exists() else []
        
        if not json_files and not md_files:
            yield event.plain_result("å„é‹å°šæœªè’é›†ï¼Œåˆè«‡ä½•å‡€åŒ–å‘¢ï¼Ÿ")
            return
        
        export_info = f"""é€™è£¡æ˜¯å„é‹çš„æºé ­ï¼Œè«‹å‹™å¿…å°å¿ƒâ€¦â€¦\n

JSONï¼š
{json_dir}
- å„é‹é»: {len(json_files)}

Markdownï¼š
{md_dir}  
- å„é‹é»: {len(md_files)}

ç¿»é–²å„é‹ä¹‹æ›¸ï¼Œä»¥æ›‰å„é‹ä¹‹æœ¬ã€‚"""
        
        yield event.plain_result(export_info)
    
    @filter.command("think_stats", alias={'å„²å­˜çµ±è¨ˆ', 'ç©ºé–“çµ±è¨ˆ'})
    async def think_stats_command(self, event: AstrMessageEvent):
        """æŸ¥çœ‹å„²å­˜çµ±è¨ˆè³‡è¨Š"""
        if not self.enable_persistence:
            yield event.plain_result("è‹¥æ˜¯æ²’æœ‰æ—¥è¨˜æœ¬ï¼Œé‚£æ€éº½è¨˜æ—¥è¨˜å‘¢ï¼ˆç¬‘ï¼‰")
            return
        
        user_id = str(event.unified_msg_origin)
        user_json_dir = self.storage_dir / 'json' / user_id
        user_md_dir = self.storage_dir / 'markdown' / user_id
        
        # çµ±è¨ˆæª”æ¡ˆæ•¸é‡å’Œå¤§å°
        json_files = list(user_json_dir.glob('*.jsonl')) if user_json_dir.exists() else []
        md_files = list(user_md_dir.glob('*.md')) if user_md_dir.exists() else []
        
        json_size = sum(f.stat().st_size for f in json_files) / 1024  # KB
        md_size = sum(f.stat().st_size for f in md_files) / 1024     # KB
        
        # çµ±è¨ˆè¨˜éŒ„æ•¸é‡
        total_records = 0
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    total_records += len(f.readlines())
            except:
                pass
        
        stats_info = f"""å„é‹è—æ›¸èˆ˜ï¼š

å„é‹æª”æ¡ˆï¼š
â€¢ JSON: {len(json_files)} å€‹ ({json_size:.1f} KB)
â€¢ Markdown: {len(md_files)} å€‹ ({md_size:.1f} KB)
â€¢ Total: {total_records} æ¢

å„é‹æ­¸å®¿ï¼š
â€¢ JSON: {user_json_dir}
â€¢ Markdown: {user_md_dir}

å„é‹åˆ¶é™ï¼š
â€¢ å–®æª”å¤§å°: {self.max_file_size_mb} MB
â€¢ å–®æª”æ¢æ•¸: {self.records_per_file} æ¢
â€¢ æª”æ¡ˆå€‹æ•¸: {self.max_records_per_user} å€‹"""
        
        yield event.plain_result(stats_info)